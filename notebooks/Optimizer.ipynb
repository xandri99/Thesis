{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL CONFIGURATION FOR THE ANALYSIS:\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append(os.getcwd().strip('notebooks') + 'src/')\n",
    "import WGCNA_functions as wgcnax\n",
    "\n",
    "\n",
    "\n",
    "# Colors for the terminal outputs\n",
    "ENDC = \"\\033[0m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "UNDERLINE = \"\\033[4m\"\n",
    "\n",
    "OKBLUE = \"\\033[94m\"\n",
    "OKGREEN = \"\\033[92m\"\n",
    "WARNING = \"\\033[93m\"\n",
    "FAIL = \"\\033[91m\"\n",
    "\n",
    "# Settings for printing dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "\n",
    "### LOADING REAL UNPUBLISHED DATA    -     NO PUSHING FOR THE RESULTS\n",
    "\n",
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('notebooks')\n",
    "data_dir = working_dir + 'data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "## Load the dataset\n",
    "# Transcriptomics Data \n",
    "transcriptomics_TPM_dataset_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_NOnormal.csv'  \n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TPM_dataset_dir, index_col=0)\n",
    "\n",
    "# Sample info and Clinical Traits Data\n",
    "sample_info_traits_dir = data_dir + 'All_Traits_Without_Normal.csv' # Using only tumor samples\n",
    "trait_dataset = pd.read_csv(sample_info_traits_dir, index_col=0)\n",
    "\n",
    "\n",
    "sample_info_traits_dir = data_dir + 'Survival_Without_Normal.csv' # Using only tumor samples\n",
    "survival_dataset = pd.read_csv(sample_info_traits_dir, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "# Figures Saving output dir\n",
    "figures_dir = working_dir + 'results/FullOptimization/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "    print(f\"{BOLD}{OKBLUE}Creating directory to save results and figures...{ENDC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Make a subset to save RAM\n",
    "subset_dataset_size = 200\n",
    "transcriptomics_dataset = transcriptomics_dataset.iloc[:, :subset_dataset_size] \n",
    "\n",
    "# RAM usage estimation in GB\n",
    "RAM_estimate = (subset_dataset_size * subset_dataset_size * 8) / (1024**3)\n",
    "print(f\"The aproximated RAM to analyse this size of dataset is: {RAM_estimate} GB\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOMATIC SEARCH FOR THE BEST PARAMETERS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS for automatic search\n",
    "\n",
    "\n",
    "# SETTINGS FOR PLOTTING FIGURES\n",
    "want_plots = False\n",
    "\n",
    "\n",
    "# Step 1.\n",
    "expression_th_vec = [0.5, 1, 1.5, 2, 5, 10]\n",
    "### As a last step, check the effect of the different preprocessing functions!!!!\n",
    "\n",
    "\n",
    "# Step 3.\n",
    "RsquaredCut_vec = [0.75, 0.85, 0.95]\n",
    "MeanCut_vec = [50, 100]\n",
    "block_size_scalefit_vec = [5, 10, 20, 30, 50]\n",
    "\n",
    "RsquaredCut = 0.9\n",
    "MeanCut = 100\n",
    "block_size_scalefit = 10\n",
    "\n",
    "adjacency_type = \"unsigned\"\n",
    "\n",
    "\n",
    "# Step 4.\n",
    "TOMDenom = \"mean\"\n",
    "\n",
    "\n",
    "# Step 6.\n",
    "min_memb_cluster_vect = [5, 10, 15, 20]\n",
    "height_percentile_vect = [70, 75, 80, 85, 90]\n",
    "\n",
    "min_memb_cluster = 10\n",
    "height_percentile = 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of  Step 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a partial search for best parameters\n",
    "# Using parameter segmentation to reduce number of iterations\n",
    "\n",
    "# Initialize the DataFrame for Results\n",
    "optimization_results = pd.DataFrame(columns=['Parameter_config', 'Num Clusters', 'Max Correlation', 'Mean Correlation',\n",
    "                                             'Num Correlations over 7', 'Mean Correlation over 7', 'Num correlations over 8'])\n",
    "\n",
    "\n",
    "\n",
    "# Optimization of the preprocessing threshold. Thus, doing full executions with the different param\n",
    "for expression_th in expression_th_vec:\n",
    "    correlations, p_values = wgcnax.run_full_WGCNA(transcriptomics_dataset, expression_th, trait_dataset, want_plots, figures_dir, \\\n",
    "                            RsquaredCut, MeanCut, block_size_scalefit, adjacency_type, TOMDenom, \\\n",
    "                            height_percentile, min_memb_cluster)\n",
    "\n",
    "\n",
    "    ## Storing results for optimization analysis\n",
    "    # Flatten the matrix to a 1D array for calculations, ignoring NaN values if any.\n",
    "    correlation_values = correlations.values.flatten()\n",
    "    correlation_values = correlation_values[~np.isnan(correlation_values)]  # Removes NaN values if present\n",
    "\n",
    "    # Calculating metrics directly from the array of correlation values.\n",
    "    num_clusters = correlations.shape[0]\n",
    "    max_correlation = np.max(np.abs(correlation_values))\n",
    "    mean_correlation = np.mean(correlation_values)\n",
    "    num_correlations_over_7 = np.sum(correlation_values > 0.7)\n",
    "    mean_correlation_over_7_values = correlation_values[correlation_values > 0.7]\n",
    "    mean_correlation_over_7 = np.mean(mean_correlation_over_7_values) if mean_correlation_over_7_values.size > 0 else np.nan\n",
    "    num_correlations_over_8 = np.sum(correlation_values > 0.8)\n",
    "\n",
    "    # Append new row to optimization_results DataFrame\n",
    "    iteration_id = \"expression_th=\" + str(expression_th)\n",
    "    \n",
    "    new_row = pd.DataFrame([{\n",
    "        'Parameter_config': iteration_id,\n",
    "        'Num Clusters': num_clusters,\n",
    "        'Max Correlation': max_correlation,\n",
    "        'Mean Correlation': mean_correlation,\n",
    "        'Num Correlations over 7': num_correlations_over_7,\n",
    "        'Mean Correlation over 7': mean_correlation_over_7,\n",
    "        'Num correlations over 8': num_correlations_over_8\n",
    "    }])\n",
    "    optimization_results = pd.concat([optimization_results, new_row], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimization_results)\n",
    "\n",
    "\n",
    "# Set the figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(15, 10))\n",
    "\n",
    "# Plotting the first subplot\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num Clusters'], label='Num Clusters', marker='o')\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num Correlations over 7'], label='Num Correlations over 7', marker='o')\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num correlations over 8'], label='Num correlations over 8', marker='o')\n",
    "ax1.set_ylabel('Counts')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plotting the second subplot\n",
    "ax2.plot(optimization_results['Parameter_config'], optimization_results['Max Correlation'], label='Max Correlation', marker='o')\n",
    "ax2.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation over 7'], label='Mean Correlation over 7', marker='o')\n",
    "ax2.set_ylabel('Correlation Values')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plotting the third subplot\n",
    "ax3.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation'], label='Mean Correlation', marker='o')\n",
    "# ax3.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation over 7'], label='Mean Correlation over 7', marker='o')\n",
    "ax3.set_ylabel('Correlation Values')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Setting the y-axis range for the second subplot\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Setting the x-axis label for the bottom subplot\n",
    "ax3.set_xlabel('Parameter_config')\n",
    "plt.xticks(rotation=90) \n",
    "\n",
    "# Improve layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of Step 3 \n",
    "pickSoftThreshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expression_th = 1.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optimization of the soft threshold Algorithm. Thus, doing full executions with the different param\n",
    "for RsquaredCut in RsquaredCut_vec:\n",
    "    for MeanCut in MeanCut_vec:\n",
    "        for block_size_scalefit in block_size_scalefit_vec:\n",
    "\n",
    "            correlations, p_values = wgcnax.run_full_WGCNA(transcriptomics_dataset, expression_th, trait_dataset, want_plots, figures_dir, \\\n",
    "                                    RsquaredCut, MeanCut, block_size_scalefit, adjacency_type, TOMDenom, \\\n",
    "                                    height_percentile, min_memb_cluster)\n",
    "\n",
    "\n",
    "            ## Storing results for optimization analysis\n",
    "            # Flatten the matrix to a 1D array for calculations, ignoring NaN values if any.\n",
    "            correlation_values = correlations.values.flatten()\n",
    "            correlation_values = correlation_values[~np.isnan(correlation_values)]  # Removes NaN values if present\n",
    "\n",
    "            # Calculating metrics directly from the array of correlation values.\n",
    "            num_clusters = correlations.shape[0]\n",
    "            max_correlation = np.max(np.abs(correlation_values))\n",
    "            mean_correlation = np.mean(correlation_values)\n",
    "            num_correlations_over_7 = np.sum(correlation_values > 0.7)\n",
    "            mean_correlation_over_7_values = correlation_values[correlation_values > 0.7]\n",
    "            mean_correlation_over_7 = np.mean(mean_correlation_over_7_values) if mean_correlation_over_7_values.size > 0 else np.nan\n",
    "            num_correlations_over_8 = np.sum(correlation_values > 0.8)\n",
    "\n",
    "            # Append new row to optimization_results DataFrame\n",
    "            iteration_id = \"RsquaredCut=\" + str(RsquaredCut) + \" MeanCut=\" + str(MeanCut) + \" block=\" + str(block_size_scalefit)\n",
    "            \n",
    "            new_row = pd.DataFrame([{\n",
    "                'Parameter_config': iteration_id,\n",
    "                'Num Clusters': num_clusters,\n",
    "                'Max Correlation': max_correlation,\n",
    "                'Mean Correlation': mean_correlation,\n",
    "                'Num Correlations over 7': num_correlations_over_7,\n",
    "                'Mean Correlation over 7': mean_correlation_over_7,\n",
    "                'Num correlations over 8': num_correlations_over_8\n",
    "            }])\n",
    "            optimization_results = pd.concat([optimization_results, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimization_results)\n",
    "\n",
    "\n",
    "# Set the figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(15, 10))\n",
    "\n",
    "# Plotting the first subplot\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num Clusters'], label='Num Clusters', marker='o')\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num Correlations over 7'], label='Num Correlations over 7', marker='o')\n",
    "ax1.plot(optimization_results['Parameter_config'], optimization_results['Num correlations over 8'], label='Num correlations over 8', marker='o')\n",
    "ax1.set_ylabel('Counts')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plotting the second subplot\n",
    "ax2.plot(optimization_results['Parameter_config'], optimization_results['Max Correlation'], label='Max Correlation', marker='o')\n",
    "ax2.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation over 7'], label='Mean Correlation over 7', marker='o')\n",
    "ax2.set_ylabel('Correlation Values')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plotting the third subplot\n",
    "ax3.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation'], label='Mean Correlation', marker='o')\n",
    "# ax3.plot(optimization_results['Parameter_config'], optimization_results['Mean Correlation over 7'], label='Mean Correlation over 7', marker='o')\n",
    "ax3.set_ylabel('Correlation Values')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Setting the y-axis range for the second subplot\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Setting the x-axis label for the bottom subplot\n",
    "ax3.set_xlabel('Parameter_config')\n",
    "plt.xticks(rotation=90) \n",
    "\n",
    "# Improve layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of Step 6\n",
    "Tree cutting algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame for Results onthis step\n",
    "optimization_results_two = pd.DataFrame(columns=['Parameter_config', 'Num Clusters', 'Max Correlation', 'Mean Correlation',\n",
    "                'Num Correlations over 5','Num Correlations over 6', 'Num correlations over 7'])\n",
    "\n",
    "\n",
    "RsquaredCut = 0.9\n",
    "MeanCut = 100\n",
    "block_size_scalefit = 5\n",
    "\n",
    "\n",
    "\n",
    "linkage_matrix, transcriptomics_dataset_filtered, trait_dataset_filtered = wgcnax.run_partialA_WGCNA(transcriptomics_dataset, \\\n",
    "                                                                            expression_th, trait_dataset, want_plots, figures_dir, \\\n",
    "                                                                            RsquaredCut, MeanCut, block_size_scalefit, adjacency_type, TOMDenom)\n",
    "\n",
    "# Optimization of the soft threshold Algorithm. Thus, doing full executions with the different param\n",
    "for min_memb_cluster in min_memb_cluster_vect:\n",
    "    for height_percentile in height_percentile_vect:\n",
    "\n",
    "            module_assignment, correlations, p_values = wgcnax.run_partialB_WGCNA(linkage_matrix, transcriptomics_dataset_filtered, \\\n",
    "                                                                trait_dataset_filtered, want_plots, figures_dir, \\\n",
    "                                                                height_percentile, min_memb_cluster)\n",
    "\n",
    "\n",
    "            ## Storing results for optimization analysis\n",
    "            # Flatten the matrix to a 1D array for calculations, ignoring NaN values if any.\n",
    "            correlation_values = correlations.values.flatten()\n",
    "            correlation_values = correlation_values[~np.isnan(correlation_values)]  # Removes NaN values if present\n",
    "\n",
    "            # Calculating metrics directly from the array of correlation values.\n",
    "            num_clusters = correlations.shape[0]\n",
    "            max_correlation = np.max(np.abs(correlation_values))\n",
    "            mean_correlation = np.mean(correlation_values)\n",
    "            num_correlations_over_5 = np.sum(np.abs(correlation_values) > 0.5)\n",
    "            num_correlations_over_6 = np.sum(np.abs(correlation_values) > 0.6)\n",
    "            num_correlations_over_7 = np.sum(np.abs(correlation_values) > 0.7)\n",
    "\n",
    "            # Append new row to optimization_results DataFrame\n",
    "            iteration_id = \"min_memb_cluster=\" + str(min_memb_cluster) + \" height_percentile=\" + str(height_percentile)\n",
    "            \n",
    "            new_row = pd.DataFrame([{\n",
    "                'Parameter_config': iteration_id,\n",
    "                'Num Clusters': num_clusters,\n",
    "                'Max Correlation': max_correlation,\n",
    "                'Mean Correlation': mean_correlation,\n",
    "                'Num Correlations over 5' : num_correlations_over_5,\n",
    "                'Num Correlations over 6': num_correlations_over_6,\n",
    "                'Num correlations over 7': num_correlations_over_7\n",
    "            }])\n",
    "            optimization_results_two = pd.concat([optimization_results_two, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimization_results_two)\n",
    "\n",
    "\n",
    "# Set the figure and axes\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(15, 10))\n",
    "\n",
    "# Plotting the first subplot\n",
    "ax1.plot(optimization_results_two['Parameter_config'], optimization_results_two['Num Clusters'], label='Num Clusters', marker='o')\n",
    "ax1.plot(optimization_results_two['Parameter_config'], optimization_results_two['Num Correlations over 5'], label='Num Correlations over 5', marker='o')\n",
    "ax1.plot(optimization_results_two['Parameter_config'], optimization_results_two['Num Correlations over 6'], label='Num correlations over 6', marker='o')\n",
    "ax1.set_ylabel('Counts')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plotting the second subplot\n",
    "ax2.plot(optimization_results_two['Parameter_config'], optimization_results_two['Max Correlation'], label='Max Correlation', marker='o')\n",
    "#ax2.plot(optimization_results_two['Parameter_config'], optimization_results_two['Mean Correlation 6<x<7'], label='Mean Correlation over 6', marker='o')\n",
    "ax2.set_ylabel('Correlation Values')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plotting the third subplot\n",
    "ax3.plot(optimization_results_two['Parameter_config'], optimization_results_two['Mean Correlation'], label='Mean Correlation', marker='o')\n",
    "# ax3.plot(optimization_results_two['Parameter_config'], optimization_results_two['Mean Correlation over 7'], label='Mean Correlation over 7', marker='o')\n",
    "ax3.set_ylabel('Correlation Values')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Setting the y-axis range for the second subplot\n",
    "ax2.set_ylim(-1, 1)\n",
    "\n",
    "# Setting the x-axis label for the bottom subplot\n",
    "ax3.set_xlabel('Parameter_config')\n",
    "plt.xticks(rotation=90) \n",
    "\n",
    "# Improve layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "FULL EXECUTION DISPLAYING ALL STEPS AND ALL PLOTS\n",
    "\n",
    "SINGLE CONFIGURATION OF PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures Saving output dir\n",
    "figures_dir = working_dir + 'results/FullOptimization/BestConfig[1.5_0.9_100_5_15_80]/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "    print(f\"{BOLD}{OKBLUE}Creating directory to save results and figures...{ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# SETTINGS FOR PLOTTING FIGURES\n",
    "want_plots = True\n",
    "\n",
    "# Step 1.\n",
    "expression_th = 1.5           # Preprocessing expression threshold\n",
    "\n",
    "# Step 3.\n",
    "RsquaredCut = 0.9\n",
    "MeanCut = 100\n",
    "block_size_scalefit = 5\n",
    "adjacency_type = \"unsigned\"\n",
    "\n",
    "# Step 4.\n",
    "TOMDenom = \"mean\"\n",
    "\n",
    "# Step 6.\n",
    "min_memb_cluster = 15\n",
    "height_percentile = 80 \n",
    "############### Using percentile 90 seems to fuck up the whole survival plot for some reason!!!\n",
    "############### Look into it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1: Data Preprocessing (Normalization)\n",
    "print(f\"{BOLD}{OKBLUE}Step 1{ENDC}\")\n",
    "transcriptomics_dataset_filtered, trait_dataset_filtered = wgcnax.preprocess_TPM_outlier_deletion(transcriptomics_dataset, expression_th, trait_dataset)\n",
    "\n",
    "\n",
    "### Step 2: Constructing a Co-expression Similarity Matrix (Correlation Matrix)\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 2{ENDC}\")\n",
    "correlation_matrix_np = wgcnax.correlation_matrix(transcriptomics_dataset_filtered, want_plots, figures_dir)\n",
    "wgcnax.matrix_np_check(correlation_matrix_np, 1, -1, 1)\n",
    "\n",
    "\n",
    "### Step 3: Transforming into an adjacency matrix using a soft threshold power\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 3{ENDC}\")\n",
    "optimal_power = wgcnax.pickSoftThreshold(correlation_matrix_np, transcriptomics_dataset_filtered, RsquaredCut, MeanCut, True, figures_dir, block_size_scalefit)\n",
    "\n",
    "adjacency_matrix_np = wgcnax.adjacencyM_from_correlationM(correlation_matrix_np, optimal_power, adjacency_type, want_plots, figures_dir)\n",
    "wgcnax.matrix_np_check(adjacency_matrix_np, 1, 0, 1)\n",
    "\n",
    "\n",
    "### Step 4: Converting adjacency matrix into a topological overlap matrix (TOM)\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 4{ENDC}\")\n",
    "simTOM_np = wgcnax.calculate_tom(adjacency_matrix_np, TOMDenom, adjacency_type, want_plots, figures_dir)\n",
    "dissTOM_np = 1 - simTOM_np\n",
    "wgcnax.matrix_np_check(simTOM_np, 1, 0, 1)\n",
    "\n",
    "\n",
    "### Step 5: Hierarchical clustering\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 5{ENDC}\")\n",
    "linkage_matrix = wgcnax.hierarchical_clustering(dissTOM_np, False, figures_dir)\n",
    "\n",
    "\n",
    "### Step 6: Module identification\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 6{ENDC}\")\n",
    "module_assignment, cut_height = wgcnax.identify_modules_simple_version(linkage_matrix, height_percentile, min_memb_cluster)\n",
    "module_assignment.insert(0, 'Gene Name', list(transcriptomics_dataset_filtered))\n",
    "\n",
    "\n",
    "### Step 7: Calculate EigenGenes for all identified Modules\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 7{ENDC}\")\n",
    "expression_profiles = wgcnax.expression_profile_for_cluster(module_assignment, transcriptomics_dataset_filtered)\n",
    "\n",
    "eigen_genes = wgcnax.calculate_eigen_genes(expression_profiles, want_plots, figures_dir)\n",
    "\n",
    "\n",
    "# Step 8.1 - Using new encoding for special variables\n",
    "print(f\"{BOLD}{OKBLUE}\\n\\nStep 8{ENDC}\")\n",
    "trait_columns = list(trait_dataset_filtered.columns[1:] )\n",
    "correlations, p_values = wgcnax.eigen_trait_correlations_DC(eigen_genes, trait_dataset_filtered, trait_columns)\n",
    "\n",
    "\n",
    "print(f\"{BOLD}{OKBLUE}Done\\n\\n{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizations\n",
    "# Plot visualization of clustersfrom scipy import stats\n",
    "\n",
    "wgcnax.plot_module_distribution(module_assignment)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plot the HEatmap\n",
    "print(f\"{BOLD}{OKBLUE}Plotting and Saving the Module EigenGene to Clinical Trait Correlation...{ENDC}\")\n",
    "title_figure = 'Module Eigengene to Clinical Trait Correlation'\n",
    "\n",
    "annotations = correlations.round(3).astype(str) + '\\n(' + p_values.round(5).astype(str) + ')'\n",
    "\n",
    "plt.figure(figsize=(40, 40)) \n",
    "sns.heatmap(correlations, annot=annotations.values, fmt='', cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "plt.title(title_figure, fontsize=20)\n",
    "plt.xlabel('Selected Clincal Traits', fontsize=10)\n",
    "plt.ylabel('Identified Modules, represented by their EigenGene', fontsize=10)\n",
    "plt.savefig(figures_dir + title_figure, dpi=150)\n",
    "plt.show()\n",
    "print(f\"{BOLD}{OKBLUE}Done{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_of_interest = 0.5\n",
    "\n",
    "\n",
    "significant_modules = []\n",
    "for trait in correlations.columns:\n",
    "    significant_clusters = correlations[trait] > threshold_of_interest\n",
    "    significant_clusters = significant_clusters[significant_clusters].index.tolist()\n",
    "    if significant_clusters:\n",
    "        for module in significant_clusters:\n",
    "            significant_modules.append(module)\n",
    "            print(f'Trait: {trait}  correlates with Module: {module}, showing a correlation of {correlations.at[module, trait]:.3f}')\n",
    "\n",
    "print('\\n')\n",
    "for module in set(significant_modules):\n",
    "    module_expression_profile = expression_profiles[expression_profiles['Module'] == module]\n",
    "    module_Genes = module_expression_profile['Gene Name'].tolist()\n",
    "    print(f'The module with id:{module} clusters {len(module_Genes)} genes.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Step 9: Survival plot\n",
    "\n",
    "# Get the modules that show high correlations\n",
    "wgcnax.survival_probability(correlations, threshold_of_interest, expression_profiles, survival_dataset, figures_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WGCNA_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
