{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node Classification with Neural Networks and Graph Neural Networks\n",
    "\n",
    "Based on the Keras guide in https://keras.io/examples/graph/gnn_citations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bxz19\\anaconda3\\envs\\GCNN\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import re\n",
    "from matplotlib_venn import venn3\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('notebooks')\n",
    "data_dir = working_dir + 'data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "## Load Transcriptomics Data \n",
    "transcriptomics_TPM_dataset_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_NOnormal.csv'  \n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TPM_dataset_dir, index_col=0)\n",
    "\n",
    "# Classification Tags\n",
    "labels_classification_dir = data_dir + 'ClassTags_PrimarySiteDisease.csv' # Using only tumor samples\n",
    "labels = pd.read_csv(labels_classification_dir, index_col=0)\n",
    "\n",
    "\n",
    "# Figures Saving output dir\n",
    "\n",
    "\n",
    "# Convert The directory to the name of the column\n",
    "trait_used_as_label = labels_classification_dir.replace(data_dir, '').replace('ClassTags_', '').replace('.csv', '')\n",
    "trait_used_as_label = re.sub(r'(?<=\\w)([A-Z])', r' \\1', trait_used_as_label) # Add spaces before the capital letters for formatting\n",
    "\n",
    "# Convert labels to categorical values\n",
    "#class_values = labels[trait_used_as_label].astype('category').cat.codes\n",
    "#labels['label'] = class_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore distribution and balance of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = labels[trait_used_as_label].value_counts()\n",
    "\n",
    "# Plotting a histogram of class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title(f'Number of Elements for Each Class in {trait_used_as_label}')\n",
    "plt.xlabel(trait_used_as_label)\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dummified Dataframe for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>AC118549.1</th>\n",
       "      <th>Primary Site Disease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.59</td>\n",
       "      <td>17.19</td>\n",
       "      <td>699.63</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.57</td>\n",
       "      <td>25.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>58.35</td>\n",
       "      <td>6.80</td>\n",
       "      <td>15.53</td>\n",
       "      <td>38.82</td>\n",
       "      <td>0.11</td>\n",
       "      <td>31.47</td>\n",
       "      <td>173.78</td>\n",
       "      <td>33.11</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15</td>\n",
       "      <td>22.14</td>\n",
       "      <td>271.97</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>33.48</td>\n",
       "      <td>24.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>42.61</td>\n",
       "      <td>6.82</td>\n",
       "      <td>14.28</td>\n",
       "      <td>40.58</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.97</td>\n",
       "      <td>220.88</td>\n",
       "      <td>50.81</td>\n",
       "      <td>12.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>23.09</td>\n",
       "      <td>221.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.10</td>\n",
       "      <td>55.10</td>\n",
       "      <td>30.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>45.46</td>\n",
       "      <td>10.10</td>\n",
       "      <td>26.16</td>\n",
       "      <td>39.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.66</td>\n",
       "      <td>198.96</td>\n",
       "      <td>35.81</td>\n",
       "      <td>16.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.14</td>\n",
       "      <td>10.17</td>\n",
       "      <td>521.99</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.44</td>\n",
       "      <td>16.39</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>17.89</td>\n",
       "      <td>9.91</td>\n",
       "      <td>21.18</td>\n",
       "      <td>33.81</td>\n",
       "      <td>0.15</td>\n",
       "      <td>23.25</td>\n",
       "      <td>208.30</td>\n",
       "      <td>26.46</td>\n",
       "      <td>23.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>7.18</td>\n",
       "      <td>123.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.44</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>19.59</td>\n",
       "      <td>4.74</td>\n",
       "      <td>9.74</td>\n",
       "      <td>25.59</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11.26</td>\n",
       "      <td>249.54</td>\n",
       "      <td>17.84</td>\n",
       "      <td>13.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>0.00</td>\n",
       "      <td>18.61</td>\n",
       "      <td>118.94</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56.81</td>\n",
       "      <td>38.55</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>73.63</td>\n",
       "      <td>7.70</td>\n",
       "      <td>15.27</td>\n",
       "      <td>31.68</td>\n",
       "      <td>0.07</td>\n",
       "      <td>23.80</td>\n",
       "      <td>218.57</td>\n",
       "      <td>47.53</td>\n",
       "      <td>19.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.00</td>\n",
       "      <td>18.95</td>\n",
       "      <td>116.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.16</td>\n",
       "      <td>39.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>29.45</td>\n",
       "      <td>6.52</td>\n",
       "      <td>15.88</td>\n",
       "      <td>32.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.61</td>\n",
       "      <td>173.41</td>\n",
       "      <td>39.83</td>\n",
       "      <td>18.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0.00</td>\n",
       "      <td>20.27</td>\n",
       "      <td>33.46</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.81</td>\n",
       "      <td>32.55</td>\n",
       "      <td>4.53</td>\n",
       "      <td>...</td>\n",
       "      <td>31.58</td>\n",
       "      <td>6.70</td>\n",
       "      <td>14.93</td>\n",
       "      <td>27.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.46</td>\n",
       "      <td>130.34</td>\n",
       "      <td>27.31</td>\n",
       "      <td>14.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>0.00</td>\n",
       "      <td>11.26</td>\n",
       "      <td>152.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>38.89</td>\n",
       "      <td>24.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>34.65</td>\n",
       "      <td>9.88</td>\n",
       "      <td>24.23</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0.12</td>\n",
       "      <td>33.09</td>\n",
       "      <td>166.38</td>\n",
       "      <td>25.96</td>\n",
       "      <td>18.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0.48</td>\n",
       "      <td>3.17</td>\n",
       "      <td>215.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.19</td>\n",
       "      <td>35.87</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>61.16</td>\n",
       "      <td>3.73</td>\n",
       "      <td>10.13</td>\n",
       "      <td>35.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>22.24</td>\n",
       "      <td>163.95</td>\n",
       "      <td>50.58</td>\n",
       "      <td>14.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows Ã— 19766 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A1BG   A1CF     A2M  A2ML1  A3GALT2  A4GALT  A4GNT   AAAS   AACS  \\\n",
       "Sample_ID                                                                     \n",
       "0          0.59  17.19  699.63   0.01     0.00   13.53   0.00  57.57  25.34   \n",
       "1          0.15  22.14  271.97   0.04     0.00   11.63   0.05  33.48  24.24   \n",
       "2          0.75  23.09  221.77   0.01     0.00    6.85   0.10  55.10  30.44   \n",
       "3          0.14  10.17  521.99   0.13     0.00   11.68   0.00  42.44  16.39   \n",
       "4          0.14   7.18  123.65   0.05     0.00   10.36   0.00  39.44  17.00   \n",
       "...         ...    ...     ...    ...      ...     ...    ...    ...    ...   \n",
       "1058       0.00  18.61  118.94   0.03     0.00    5.55   0.00  56.81  38.55   \n",
       "1059       0.00  18.95  116.77   0.03     0.00    2.18   0.00  44.16  39.94   \n",
       "1060       0.00  20.27   33.46   0.15     0.19    5.10   0.00  31.81  32.55   \n",
       "1061       0.00  11.26  152.04   0.11     0.00    9.38   0.10  38.89  24.80   \n",
       "1062       0.48   3.17  215.11   0.00     0.00   18.98   0.00  55.19  35.87   \n",
       "\n",
       "           AADAC  ...  ZWINT   ZXDA   ZXDB   ZXDC  ZYG11A  ZYG11B     ZYX  \\\n",
       "Sample_ID         ...                                                       \n",
       "0           0.00  ...  58.35   6.80  15.53  38.82    0.11   31.47  173.78   \n",
       "1           0.10  ...  42.61   6.82  14.28  40.58    0.04   19.97  220.88   \n",
       "2           0.83  ...  45.46  10.10  26.16  39.23    0.00   21.66  198.96   \n",
       "3           0.15  ...  17.89   9.91  21.18  33.81    0.15   23.25  208.30   \n",
       "4           1.49  ...  19.59   4.74   9.74  25.59    0.15   11.26  249.54   \n",
       "...          ...  ...    ...    ...    ...    ...     ...     ...     ...   \n",
       "1058        0.21  ...  73.63   7.70  15.27  31.68    0.07   23.80  218.57   \n",
       "1059        0.34  ...  29.45   6.52  15.88  32.49    0.00   16.61  173.41   \n",
       "1060        4.53  ...  31.58   6.70  14.93  27.05    0.04   12.46  130.34   \n",
       "1061        0.96  ...  34.65   9.88  24.23  34.96    0.12   33.09  166.38   \n",
       "1062        0.14  ...  61.16   3.73  10.13  35.38    0.25   22.24  163.95   \n",
       "\n",
       "           ZZEF1  AC118549.1  Primary Site Disease  \n",
       "Sample_ID                                           \n",
       "0          33.11       17.82                     0  \n",
       "1          50.81       12.90                     1  \n",
       "2          35.81       16.74                     1  \n",
       "3          26.46       23.62                     1  \n",
       "4          17.84       13.08                     1  \n",
       "...          ...         ...                   ...  \n",
       "1058       47.53       19.17                     1  \n",
       "1059       39.83       18.48                     1  \n",
       "1060       27.31       14.83                     0  \n",
       "1061       25.96       18.43                     0  \n",
       "1062       50.58       14.72                     1  \n",
       "\n",
       "[1063 rows x 19766 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merge the Labels column (with the selected clinical trail) with the transcriptomics dataset\n",
    "transcriptomics_labeled_df = pd.merge(left=transcriptomics_dataset, left_index=True, right=labels, right_index=True, how='inner')\n",
    "\n",
    "\n",
    "## We convert the Samples ids and the Labels into zero-based indices.\n",
    "class_values = labels[trait_used_as_label].unique()\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "pacient_idx = {name: idx for idx, name in enumerate(transcriptomics_dataset.index.unique())}\n",
    "\n",
    "\n",
    "## We update the dataframe with this dummified values\n",
    "transcriptomics_labeled_df = transcriptomics_labeled_df.rename(index=pacient_idx)\n",
    "transcriptomics_labeled_df[trait_used_as_label] = transcriptomics_labeled_df[trait_used_as_label].apply(lambda name: class_idx[name])\n",
    "transcriptomics_labeled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into stratified Train, Test and Validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, validation_data = [], [], []\n",
    "\n",
    "# Create train and test splits\n",
    "for _, group_data in transcriptomics_labeled_df.groupby(trait_used_as_label):\n",
    "    # Declare the % of train, test, validate\n",
    "    train_split = 0.7\n",
    "    test_split = 0.2\n",
    "    \n",
    "    # Build the subsets for each category\n",
    "    random_selection = np.random.rand(len(group_data.index))\n",
    "    train_subset = random_selection <= train_split\n",
    "    test_subset = (random_selection > train_split) & (random_selection <= (train_split + test_split))\n",
    "    val_subset = random_selection > (train_split + test_split)\n",
    "\n",
    "    # Reformat the data\n",
    "    train_data.append(group_data[train_subset])\n",
    "    test_data.append(group_data[test_subset])\n",
    "    validation_data.append(group_data[val_subset])\n",
    "\n",
    "# Concatenate and shuffle the subsets from each group\n",
    "train_data = pd.concat(train_data).sample(frac=1)\n",
    "test_data = pd.concat(test_data).sample(frac=1)\n",
    "validation_data = pd.concat(validation_data).sample(frac=1)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Validation data shape:\", validation_data.shape)\n",
    "\n",
    "\n",
    "# Plot Venn diagram to visualize overlap\n",
    "venn3([set(train_data.index), set(test_data.index), set(validation_data.index)], ('Train', 'Test', 'Validation'))\n",
    "plt.title(\"Overlap between Train, Test, and Validation Sets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the genes's names, removing the label column\n",
    "feature_names = list(set(transcriptomics_labeled_df.columns) - {trait_used_as_label})\n",
    "num_features = len(feature_names)\n",
    "num_classes = len(class_idx)\n",
    "\n",
    "## Create train,test and validation features as a numpy array.\n",
    "x_train = train_data[feature_names].to_numpy()\n",
    "x_test = test_data[feature_names].to_numpy()\n",
    "x_validation = validation_data[feature_names].to_numpy()\n",
    "\n",
    "## Create train and test targets as a numpy array.\n",
    "y_train = train_data[trait_used_as_label]\n",
    "y_test = test_data[trait_used_as_label]\n",
    "y_validation = validation_data[trait_used_as_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Train and Evaluate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter configuration - Standard values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [32, 32]\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.5\n",
    "num_epochs = 300\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions compiles and trains an input model using the given training data, displays the loss and accuracy curves, and Implement Feedforward Network (FFN) Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, x_train, y_train, x_test, y_test):\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "    )\n",
    "    # Create an early stopping callback.\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\", patience=50, restore_best_weights=True\n",
    "    )\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"acc\"])\n",
    "    ax2.plot(history.history[\"val_acc\"])\n",
    "    ax2.legend([\"train\", \"test\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "def create_ffn(hidden_units, dropout_rate, name=None):\n",
    "    fnn_layers = []\n",
    "\n",
    "    for units in hidden_units:\n",
    "        fnn_layers.append(layers.BatchNormalization())\n",
    "        fnn_layers.append(layers.Dropout(dropout_rate))\n",
    "        fnn_layers.append(layers.Dense(units, activation=tf.nn.gelu))\n",
    "\n",
    "    return keras.Sequential(fnn_layers, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Baseline Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(hidden_units, num_classes, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=(num_features,), name=\"input_features\")\n",
    "    x = create_ffn(hidden_units, dropout_rate, name=f\"ffn_block1\")(inputs)\n",
    "    for block_idx in range(4):\n",
    "        # Create an FFN block.\n",
    "        x1 = create_ffn(hidden_units, dropout_rate, name=f\"ffn_block{block_idx + 2}\")(x)\n",
    "        # Add skip connection.\n",
    "        x = layers.Add(name=f\"skip_connection{block_idx + 2}\")([x, x1])\n",
    "    # Compute logits.\n",
    "    logits = layers.Dense(num_classes, name=\"logits\")(x)\n",
    "    # Create the model.\n",
    "    return keras.Model(inputs=inputs, outputs=logits, name=\"baseline\")\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model(hidden_units, num_classes, dropout_rate)\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "history = run_training(baseline_model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the baseline model on the VALIDATION data split. \n",
    "_, test_accuracy = baseline_model.evaluate(x=x_validation, y=y_validation, verbose=0)\n",
    "print(f\"Test accuracy: {round(test_accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Graph Neural Network Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Graph from the data, to feed it to the GNN\n",
    "\n",
    "For this example, we will use the simplest approach to this, that it consists on building a simple correlation matrix between the pacients, and not the genes.\n",
    "This approach shall be improved in further version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this architecutre, each node is a pacient, and the node features is the full transcriptome of that pacient [num_nodes, num_features]\n",
    "node_features = tf.cast(transcriptomics_labeled_df[feature_names].to_numpy(), dtype=tf.dtypes.float32) # We keep the label out!!\n",
    "\n",
    "\n",
    "\n",
    "## The links will be the correlation between pacients, and the weight the strength of the correlation\n",
    "# Turn dataframe into NumPy matrix for efficiency\n",
    "transcriptomics_np = transcriptomics_labeled_df.to_numpy()\n",
    "\n",
    "# Calculate Correlation matrix (correlation between pacients)\n",
    "pacients_correlation_matrix, _ = stats.spearmanr(transcriptomics_np, axis=1)\n",
    "\n",
    "# Normalize edge weights and adjust self-connections\n",
    "pacients_correlation_matrix = (pacients_correlation_matrix + 1) / 2\n",
    "np.fill_diagonal(pacients_correlation_matrix, 0)\n",
    "pacients_correlation_matrix = np.clip(pacients_correlation_matrix, 0, 1)\n",
    "\n",
    "# Flatten the correlation matrix (only upper half) (excluding the diagonal (k=1))\n",
    "rows, cols = np.triu_indices(n=pacients_correlation_matrix.shape[0], k=1)\n",
    "flat_edge_weights = pacients_correlation_matrix[rows, cols]\n",
    "edge_weights = tf.constant(flat_edge_weights, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "## Create the edges array\n",
    "edges = np.vstack((rows, cols))\n",
    "\n",
    "\n",
    "# Create graph info tuple with node_features, edges, and edge_weights.\n",
    "graph_info = (node_features, edges, edge_weights)\n",
    "\n",
    "\n",
    "# Display shapes of node_features and edge_weights\n",
    "print(\"Node Features shape:\", node_features.shape)\n",
    "print(\"Edges shape:\", edges.shape)\n",
    "print(\"Edge Weights shape:\", edge_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a graph convolution layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_gru(hidden_units, dropout_rate):\n",
    "    inputs = keras.layers.Input(shape=(2, hidden_units[0]))\n",
    "    x = inputs\n",
    "    for units in hidden_units:\n",
    "      x = layers.GRU(\n",
    "          units=units,\n",
    "          activation=\"tanh\",\n",
    "          recurrent_activation=\"sigmoid\",\n",
    "          return_sequences=True,\n",
    "          dropout=dropout_rate,\n",
    "          return_state=False,\n",
    "          recurrent_dropout=dropout_rate,\n",
    "      )(x)\n",
    "    return keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_units,\n",
    "        dropout_rate=0.2,\n",
    "        aggregation_type=\"mean\",\n",
    "        combination_type=\"concat\",\n",
    "        normalize=False,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.combination_type = combination_type\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.ffn_prepare = create_ffn(hidden_units, dropout_rate)\n",
    "        if self.combination_type == \"gru\":\n",
    "            self.update_fn = create_gru(hidden_units, dropout_rate)\n",
    "        else:\n",
    "            self.update_fn = create_ffn(hidden_units, dropout_rate)\n",
    "\n",
    "    def prepare(self, node_repesentations, weights=None):\n",
    "        # node_repesentations shape is [num_edges, embedding_dim].\n",
    "        messages = self.ffn_prepare(node_repesentations)\n",
    "        if weights is not None:\n",
    "            messages = messages * tf.expand_dims(weights, -1)\n",
    "        return messages\n",
    "\n",
    "    def aggregate(self, node_indices, neighbour_messages, node_repesentations):\n",
    "        # node_indices shape is [num_edges].\n",
    "        # neighbour_messages shape: [num_edges, representation_dim].\n",
    "        # node_repesentations shape is [num_nodes, representation_dim].\n",
    "        num_nodes = node_repesentations.shape[0]\n",
    "        if self.aggregation_type == \"sum\":\n",
    "            aggregated_message = tf.math.unsorted_segment_sum(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"mean\":\n",
    "            aggregated_message = tf.math.unsorted_segment_mean(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            aggregated_message = tf.math.unsorted_segment_max(\n",
    "                neighbour_messages, node_indices, num_segments=num_nodes\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid aggregation type: {self.aggregation_type}.\")\n",
    "\n",
    "        return aggregated_message\n",
    "\n",
    "    def update(self, node_repesentations, aggregated_messages):\n",
    "        # node_repesentations shape is [num_nodes, representation_dim].\n",
    "        # aggregated_messages shape is [num_nodes, representation_dim].\n",
    "        if self.combination_type == \"gru\":\n",
    "            # Create a sequence of two elements for the GRU layer.\n",
    "            h = tf.stack([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"concat\":\n",
    "            # Concatenate the node_repesentations and aggregated_messages.\n",
    "            h = tf.concat([node_repesentations, aggregated_messages], axis=1)\n",
    "        elif self.combination_type == \"add\":\n",
    "            # Add node_repesentations and aggregated_messages.\n",
    "            h = node_repesentations + aggregated_messages\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid combination type: {self.combination_type}.\")\n",
    "\n",
    "        # Apply the processing function.\n",
    "        node_embeddings = self.update_fn(h)\n",
    "        if self.combination_type == \"gru\":\n",
    "            node_embeddings = tf.unstack(node_embeddings, axis=1)[-1]\n",
    "\n",
    "        if self.normalize:\n",
    "            node_embeddings = tf.nn.l2_normalize(node_embeddings, axis=-1)\n",
    "        return node_embeddings\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Process the inputs to produce the node_embeddings.\n",
    "\n",
    "        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.\n",
    "        Returns: node_embeddings of shape [num_nodes, representation_dim].\n",
    "        \"\"\"\n",
    "\n",
    "        node_repesentations, edges, edge_weights = inputs\n",
    "        # Get node_indices (source) and neighbour_indices (target) from edges.\n",
    "        node_indices, neighbour_indices = edges[0], edges[1]\n",
    "        # neighbour_repesentations shape is [num_edges, representation_dim].\n",
    "        neighbour_repesentations = tf.gather(node_repesentations, neighbour_indices)\n",
    "\n",
    "        # Prepare the messages of the neighbours.\n",
    "        neighbour_messages = self.prepare(neighbour_repesentations, edge_weights)\n",
    "        # Aggregate the neighbour messages.\n",
    "        aggregated_messages = self.aggregate(\n",
    "            node_indices, neighbour_messages, node_repesentations\n",
    "        )\n",
    "        # Update the node embedding with the neighbour messages.\n",
    "        return self.update(node_repesentations, aggregated_messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a graph neural network node classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNNodeClassifier(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_info,\n",
    "        num_classes,\n",
    "        hidden_units,\n",
    "        aggregation_type=\"sum\",\n",
    "        combination_type=\"concat\",\n",
    "        dropout_rate=0.2,\n",
    "        normalize=True,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # Unpack graph_info to three elements: node_features, edges, and edge_weight.\n",
    "        node_features, edges, edge_weights = graph_info\n",
    "        self.node_features = node_features\n",
    "        self.edges = edges\n",
    "        self.edge_weights = edge_weights\n",
    "        # Set edge_weights to ones if not provided.\n",
    "        if self.edge_weights is None:\n",
    "            self.edge_weights = tf.ones(shape=edges.shape[1])\n",
    "        # Scale edge_weights to sum to 1.\n",
    "        self.edge_weights = self.edge_weights / tf.math.reduce_sum(self.edge_weights)\n",
    "\n",
    "        # Create a process layer.\n",
    "        self.preprocess = create_ffn(hidden_units, dropout_rate, name=\"preprocess\")\n",
    "        # Create the first GraphConv layer.\n",
    "        self.conv1 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv1\",\n",
    "        )\n",
    "        # Create the second GraphConv layer.\n",
    "        self.conv2 = GraphConvLayer(\n",
    "            hidden_units,\n",
    "            dropout_rate,\n",
    "            aggregation_type,\n",
    "            combination_type,\n",
    "            normalize,\n",
    "            name=\"graph_conv2\",\n",
    "        )\n",
    "        # Create a postprocess layer.\n",
    "        self.postprocess = create_ffn(hidden_units, dropout_rate, name=\"postprocess\")\n",
    "        # Create a compute logits layer.\n",
    "        self.compute_logits = layers.Dense(units=num_classes, name=\"logits\")\n",
    "\n",
    "    def call(self, input_node_indices):\n",
    "        # Preprocess the node_features to produce node representations.\n",
    "        x = self.preprocess(self.node_features)\n",
    "        # Apply the first graph conv layer.\n",
    "        x1 = self.conv1((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x1 + x\n",
    "        # Apply the second graph conv layer.\n",
    "        x2 = self.conv2((x, self.edges, self.edge_weights))\n",
    "        # Skip connection.\n",
    "        x = x2 + x\n",
    "        # Postprocess node embedding.\n",
    "        x = self.postprocess(x)\n",
    "        # Fetch node embeddings for the input node_indices.\n",
    "        node_embeddings = tf.gather(x, input_node_indices)\n",
    "        # Compute logits\n",
    "        return self.compute_logits(node_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and summary of the GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_model = GNNNodeClassifier(\n",
    "    graph_info=graph_info,\n",
    "    num_classes=num_classes,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rate=dropout_rate,\n",
    "    name=\"gnn_model\",\n",
    ")\n",
    "\n",
    "print(\"GNN output shape:\", gnn_model([1, 10, 100]))\n",
    "\n",
    "gnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Display Learning Curves for the GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "x_train = train_data.index.to_numpy()\n",
    "x_test = test_data.index.to_numpy()\n",
    "\n",
    "history = run_training(gnn_model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "display_learning_curves(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = validation_data.index.to_numpy()\n",
    "\n",
    "_, test_accuracy = gnn_model.evaluate(x=x_validation, y=y_validation, verbose=0)\n",
    "print(f\"Test accuracy: {round(test_accuracy * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
