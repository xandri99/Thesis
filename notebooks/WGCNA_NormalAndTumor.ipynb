{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to run the WGCNA calling for the functions from the py file. To implement once the method is functioning correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL CONFIGURATION FOR THE ANALYSIS:\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "sys.path.append(os.getcwd().strip('notebooks') + 'src/')\n",
    "import WGCNA_functions as wgcnax\n",
    "import importlib\n",
    "importlib.reload(wgcnax)\n",
    "\n",
    "\n",
    " # Save work session for easy execution on plots\n",
    "import dill\n",
    "\n",
    "\n",
    "\n",
    "# Colors for the terminal outputs\n",
    "ENDC = \"\\033[0m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "UNDERLINE = \"\\033[4m\"\n",
    "\n",
    "OKBLUE = \"\\033[94m\"\n",
    "OKGREEN = \"\\033[92m\"\n",
    "WARNING = \"\\033[93m\"\n",
    "FAIL = \"\\033[91m\"\n",
    "\n",
    "# Settings for printing dataframes\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS FOR PLOTTING FIGURES\n",
    "want_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING REAL UNPUBLISHED DATA    -     NO PUSHING FOR THE RESULTS\n",
    "\n",
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('notebooks')\n",
    "data_dir = working_dir + 'data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "\n",
    "## Load the dataset\n",
    "# Transcriptomics Data \n",
    "transcriptomics_All_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM.csv'\n",
    "transcriptomics_TumorOnly_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_TumorOnly.csv'\n",
    "transcriptomics_NormalOnly_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_NormalOnly.csv'\n",
    "\n",
    "transcriptomics_All = pd.read_csv(transcriptomics_All_dir, index_col=0)\n",
    "transcriptomics_TumorOnly = pd.read_csv(transcriptomics_TumorOnly_dir, index_col=0)\n",
    "transcriptomics_NormalOnly = pd.read_csv(transcriptomics_NormalOnly_dir, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "# Clinical Traits Data\n",
    "CT_for_All_dir = data_dir + 'ClinicalTraits_for_AllSamples.csv'\n",
    "CT_for_TumorSamples_dir = data_dir + 'ClinicalTraits_for_TumorSamples.csv'\n",
    "CT_for_NormalSamples_dir = data_dir + 'ClinicalTraits_for_NormalSamples.csv'\n",
    "\n",
    "CT_for_All = pd.read_csv(CT_for_All_dir, index_col=0)\n",
    "CT_for_TumorSamples = pd.read_csv(CT_for_TumorSamples_dir, index_col=0)\n",
    "CT_for_NormalSamples = pd.read_csv(CT_for_NormalSamples_dir, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "# Survival Data\n",
    "SurvivalData_for_TumorSamples_dir = data_dir + 'Survival_Data_for_TumorSamples.csv' # Using only tumor samples\n",
    "SurvivalData_for_TumorSamples = pd.read_csv(SurvivalData_for_TumorSamples_dir, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "# Figures Saving output dir\n",
    "figures_dir = working_dir + 'results/NormalandTumor_usingOnlyTumor_bestConfig/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "    print(f\"{BOLD}{OKBLUE}Creating directory to save results and figures...{ENDC}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## WE WANT TO USE ALL DATA FOR CLUSTERING, AND THEN SEPARATE TYPES OF SAMPLES IN THE EIGENGENE STEP\n",
    "transcriptomics_dataset = transcriptomics_All\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "## Make a subset to save RAM\n",
    "subset_dataset_size = 200\n",
    "transcriptomics_dataset = transcriptomics_dataset.iloc[:, :subset_dataset_size] \n",
    "\n",
    "# RAM usage estimation in GB\n",
    "RAM_estimate = (subset_dataset_size * subset_dataset_size * 8) / (1024**3)\n",
    "print(f\"The aproximated RAM to analyse this size of dataset is: {RAM_estimate} GB\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1: Data Preprocessing (Normalization)\n",
    "\n",
    "\n",
    "# Visualize original and preprocessed data with PCA\n",
    "# Create a 2x2 subplot grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot each PCA visualization\n",
    "expression_th = 1.5\n",
    "\n",
    "wgcnax.plot_pca(transcriptomics_dataset, title='PCA of Original Data', ax=axs[0, 0])\n",
    "wgcnax.plot_pca(wgcnax.simple_preprocess(transcriptomics_dataset), title='PCA of Preprocessed with simple_preprocess', ax=axs[0, 1])\n",
    "wgcnax.plot_pca(wgcnax.preprocess_TPM(transcriptomics_dataset, expression_th), title='PCA of Preprocessed with preprocess_TPM', ax=axs[1, 0])\n",
    "datasetttt, traitsss = wgcnax.preprocess_TPM_outlier_deletion(transcriptomics_dataset, expression_th, CT_for_All)\n",
    "wgcnax.plot_pca(datasetttt, title='PCA of Preprocessed with preprocess_TPM_outlier_deletion', ax=axs[1, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Basic Preprocessing, Expected to perform the worst\n",
    "# transcriptomics_dataset_filtered = wgcnax.preprocess_TPM(transcriptomics_dataset, expression_th)\n",
    "\n",
    "\n",
    "# Zscore, expected to perform a bit better than with Basic TPM, but still not great\n",
    "#transcriptomics_dataset_filtered = wgcnax.preprocess_TPM_Zscore(transcriptomics_dataset, expression_th)\n",
    "\n",
    "\n",
    "# PCA Analysis, which should be the best one by a lot\n",
    "transcriptomics_dataset_filtered, CT_for_All_filtered = wgcnax.preprocess_TPM_outlier_deletion(transcriptomics_dataset, expression_th, CT_for_All)\n",
    "\n",
    "\n",
    "# Super agressive Preprocessing from the paper on GCNN - Performs a lot worse\n",
    "#transcriptomics_dataset_filtered = wgcnax.preprocess_agresive(transcriptomics_dataset)\n",
    "#wgcnax.plot_pca(transcriptomics_dataset_filtered, title='PCA of Agressive Preproces')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{BOLD}{OKBLUE}Done...{ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2: Constructing a Co-expression Similarity Matrix (Correlation Matrix)\n",
    "\n",
    "correlation_matrix_np = wgcnax.correlation_matrix(transcriptomics_dataset_filtered, want_plots, figures_dir)\n",
    "\n",
    "wgcnax.matrix_np_check(correlation_matrix_np, 1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Transforming into an adjacency matrix using a soft threshold power\n",
    "\n",
    "## Parameters for execution.\n",
    "RsquaredCut = 0.9\n",
    "MeanCut = 100\n",
    "block_size_scalefit = 5\n",
    "adjacency_type = \"unsigned\"\n",
    "\n",
    "\n",
    "# Get the optimal power for the adjacency matrix (fitting to a power-law distritbution)\n",
    "optimal_power = wgcnax.pickSoftThreshold(correlation_matrix_np, transcriptomics_dataset_filtered, RsquaredCut, MeanCut, want_plots, figures_dir, block_size_scalefit)\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adjacency_matrix_np = wgcnax.adjacencyM_from_correlationM(correlation_matrix_np, optimal_power, adjacency_type, want_plots, figures_dir)\n",
    "wgcnax.matrix_np_check(adjacency_matrix_np, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 4: Converting adjacency matrix into a topological overlap matrix (TOM)\n",
    "\n",
    "# TOMDenom must be either 'min' or 'mean'. More explanation in the function itself\n",
    "TOMDenom = \"mean\"\n",
    "\n",
    "# Get the TOM matrix\n",
    "simTOM_np = wgcnax.calculate_tom(adjacency_matrix_np, TOMDenom, adjacency_type, want_plots, figures_dir)\n",
    "dissTOM_np = 1 - simTOM_np\n",
    "wgcnax.matrix_np_check(simTOM_np, 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 5: Hierarchical clustering\n",
    "linkage_matrix = wgcnax.hierarchical_clustering(dissTOM_np, want_plots, figures_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 6: Module identification\n",
    "\n",
    "#Parameters\n",
    "min_memb_cluster = 10    # 15 seems to be optimal\n",
    "height_percentile = 80  \n",
    "\n",
    "module_assignment, cut_height = wgcnax.identify_modules_simple_version(linkage_matrix, height_percentile, min_memb_cluster)\n",
    "\n",
    "# Add the Gene name to the clustering table\n",
    "module_assignment.insert(0, 'Gene Name', list(transcriptomics_dataset_filtered))\n",
    "\n",
    "# Plot visualization of clusters\n",
    "wgcnax.plot_module_distribution(module_assignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Step 6: Module identification - SECOND METHOD\n",
    "\n",
    "module_assignment_sec, cut_height = wgcnax.identify_modules_auto_deep_split(linkage_matrix, dissTOM_np, min_memb_cluster)\n",
    "\n",
    "# Add the Gene name to the clustering table\n",
    "module_assignment_sec.insert(0, 'Gene Name', list(transcriptomics_dataset_filtered))\n",
    "\n",
    "# Plot visualization of clusters\n",
    "wgcnax.plot_module_distribution(module_assignment_sec)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation into 3 segmented analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we built the Flat Clusters using all samples (Tumor and Normal), and now we will separate them:\n",
    "  - Eigengene for Normal Samples only\n",
    "  - Eigengene for Tumor Samples only\n",
    "  - Eigengene with All Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separated to study effect of using all samples or only tumor in final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build 3 datasated containing: Only Tumor Samples, only Normal Samples, and both.\n",
    "Transc_TumorOnly = transcriptomics_dataset_filtered[transcriptomics_dataset_filtered.index.isin(transcriptomics_TumorOnly.index)]\n",
    "Transc_NormalOnly = transcriptomics_dataset_filtered[transcriptomics_dataset_filtered.index.isin(transcriptomics_NormalOnly.index)]\n",
    "Transc_All = transcriptomics_dataset_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is intersting to observe that PCA outlier detection eliminates 11 samples, all from the Normal Samples.\n",
    "\n",
    "print(Transc_TumorOnly.shape)\n",
    "print(Transc_NormalOnly.shape)\n",
    "print(Transc_All.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(CT_for_TumorSamples.shape)\n",
    "print(CT_for_NormalSamples.shape)\n",
    "print(CT_for_All.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not running PCA\n",
    "# CT_for_All_filtered = CT_for_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ensure that the PCA Sample Outlier Detection is applied to all CT dataset\n",
    "CT_for_TumorSamples_filtered = CT_for_TumorSamples[CT_for_TumorSamples.index.isin(CT_for_All_filtered.index)]\n",
    "CT_for_NormalSamples_filtered = CT_for_NormalSamples[CT_for_NormalSamples.index.isin(CT_for_All_filtered.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 7: Calculate EigenGenes for all identified Modules, for each configuration of Samples\n",
    "\n",
    "## Tumor only Eigengenes\n",
    "TumorOnly_expression_profiles = wgcnax.expression_profile_for_cluster(module_assignment, Transc_TumorOnly)\n",
    "TumorOnly_eigen_genes = wgcnax.calculate_eigen_genes(TumorOnly_expression_profiles, want_plots, figures_dir)\n",
    "\n",
    "## Normal only Eigengenes\n",
    "NormalOnly_expression_profiles = wgcnax.expression_profile_for_cluster(module_assignment, Transc_NormalOnly)\n",
    "NormalOnly_eigen_genes = wgcnax.calculate_eigen_genes(NormalOnly_expression_profiles, want_plots, figures_dir)\n",
    "\n",
    "## All Normal and Tumor Samples Eigengenes\n",
    "All_expression_profiles = wgcnax.expression_profile_for_cluster(module_assignment, Transc_All)\n",
    "All_eigen_genes = wgcnax.calculate_eigen_genes(All_expression_profiles, want_plots, figures_dir)\n",
    "\n",
    "\n",
    "if TumorOnly_eigen_genes.shape[1] != 1064 or NormalOnly_eigen_genes.shape[1] != 121 or All_expression_profiles.shape[1] != 1185:\n",
    "    print(f\"Something is wrong, the dimensions are not matching the expected size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 8: Module-Trait Relationship\n",
    "# Plot 3 Heatmaps, to separate between effect in Tumor vs. Normal\n",
    "\n",
    "p_value_th = 0.05\n",
    "\n",
    "# TUMOR SAMPLES ONLY\n",
    "trait_columns = list(CT_for_TumorSamples.columns[1:] )\n",
    "correlations_T, p_values_T = wgcnax.eigen_trait_correlations_DC(TumorOnly_eigen_genes, CT_for_TumorSamples_filtered, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_T, p_values_T, figures_dir, title = 'Tumor Samples Only', p_value_th=p_value_th)\n",
    "\n",
    "\n",
    "# Normal SAMPLES ONLY\n",
    "trait_columns = list(CT_for_NormalSamples.columns[1:] )\n",
    "correlations_N, p_values_N = wgcnax.eigen_trait_correlations_DC(NormalOnly_eigen_genes, CT_for_NormalSamples_filtered, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_N, p_values_N, figures_dir, title = 'Normal Samples Only', p_value_th=p_value_th)\n",
    "\n",
    "\n",
    "# All SAMPLES\n",
    "trait_columns = list(CT_for_All.columns[1:] )\n",
    "correlations_TN, p_values_TN = wgcnax.eigen_trait_correlations_DC(All_eigen_genes, CT_for_All_filtered, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_TN, p_values_TN, figures_dir, title = 'All Samples', p_value_th=p_value_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### More Special Heatmaps -- Not relevant\n",
    "\n",
    "\n",
    "#### All SAMPLES correlated with Tumor or Normal Tissue\n",
    "\n",
    "## Create Dataframe with all samples, annotated as Tumor or Normal Sample\n",
    "CT_for_All_filtered.reset_index(inplace=True)\n",
    "All_Samples_Labeled = CT_for_All_filtered[['Sample_ID']].copy()\n",
    "All_Samples_Labeled['SampleType'] = 0\n",
    "\n",
    "# If it contains 'T', mark 'Tumor' as 1, if it contains 'N', mark as 0\n",
    "All_Samples_Labeled['SampleType'] = All_Samples_Labeled['Sample_ID'].apply(\n",
    "    lambda sample_id: 'Tumor' if 'T' in sample_id else ('Normal' if 'N' in sample_id else None))\n",
    "\n",
    "# Plot Heatmap\n",
    "trait_columns = list(All_Samples_Labeled.columns[1:] )\n",
    "correlations_TNL, p_values_TNL = wgcnax.eigen_trait_correlations_DC(All_eigen_genes, All_Samples_Labeled, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_TNL, p_values_TNL, figures_dir, title = 'All Samples, Labeled', p_value_th=p_value_th)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Tumor only HeatMap, splitted by Male or Female\n",
    "\n",
    "# Initialize dictionaries to store columns for each gender, and avoid high fragmentation\n",
    "columns_male = {'Module': TumorOnly_eigen_genes['Module']}\n",
    "columns_female = {'Module': TumorOnly_eigen_genes['Module']}\n",
    "\n",
    "for sample_id in TumorOnly_eigen_genes.columns.drop('Module'):\n",
    "    if sample_id in CT_for_TumorSamples_filtered.index:\n",
    "        gender = CT_for_TumorSamples_filtered.loc[sample_id, 'Gender']\n",
    "\n",
    "        # Based on the gender, add the column to the corresponding dictionary\n",
    "        if gender == 'Male':\n",
    "            columns_male[sample_id] = TumorOnly_eigen_genes[sample_id]\n",
    "        elif gender == 'Female':\n",
    "            columns_female[sample_id] = TumorOnly_eigen_genes[sample_id]\n",
    "\n",
    "# Concatenate all the collected columns at once for males and females\n",
    "TumorOnly_eigen_genes_Male = pd.DataFrame(columns_male)\n",
    "TumorOnly_eigen_genes_Female = pd.DataFrame(columns_female)\n",
    "\n",
    "# Split the ClinicalTrait dataframe also into Female Male\n",
    "CT_for_TumorSamples_Female = CT_for_TumorSamples_filtered[CT_for_TumorSamples_filtered['Gender'] == 'Female'].drop('Gender', axis=1) \n",
    "CT_for_TumorSamples_Male = CT_for_TumorSamples_filtered[CT_for_TumorSamples_filtered['Gender'] == 'Male'].drop('Gender', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Plot Heatmap for Males\n",
    "trait_columns = list(CT_for_TumorSamples_Male.columns[1:] )\n",
    "correlations_TM, p_values_TM = wgcnax.eigen_trait_correlations_DC(TumorOnly_eigen_genes_Male, CT_for_TumorSamples_Male, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_TM, p_values_TM, figures_dir, title = 'Tumor and Male Only', p_value_th=p_value_th)\n",
    "\n",
    "\n",
    "# Plot Heatmap for Females\n",
    "trait_columns = list(CT_for_TumorSamples_Female.columns[1:] )\n",
    "correlations_TM, p_values_TM = wgcnax.eigen_trait_correlations_DC(TumorOnly_eigen_genes_Female, CT_for_TumorSamples_Female, trait_columns)\n",
    "## Plot the Heatmap for the module-trait relationship\n",
    "wgcnax.correlation_heatmap(correlations_TM, p_values_TM, figures_dir, title = 'Tumor and Female Only', p_value_th=p_value_th)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, after checking everything, seems to be more relevant to keep the samples separated (normal and tumor segregated), and to keep genders toghether. Now, we can study the effect of this configuration in everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve visualization and do Results selection on the interesting heatmap\n",
    "\n",
    "in this case, only Tumor Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select what heatmap you want\n",
    "correlations = correlations_T\n",
    "p_values = p_values_T\n",
    "expression_profiles = TumorOnly_expression_profiles\n",
    "eigengenes = TumorOnly_eigen_genes\n",
    "\n",
    "\n",
    "# Find rows where all cells have abs(value) < 0.45 and drope them\n",
    "threshold_of_interest = 0.5\n",
    "\n",
    "# Filter out non relevant modules\n",
    "not_significant_modules = (correlations.abs() < threshold_of_interest).all(axis=1)\n",
    "modules_to_drop = correlations.index[not_significant_modules]\n",
    "print(f\"The following Modules are droped: {list(modules_to_drop)}\")\n",
    "correlations_filtered = correlations.drop(index=modules_to_drop)\n",
    "p_values_filtered = p_values.drop(index=modules_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filtered Heatmap, displaying only reelevant clusters\n",
    "\n",
    "wgcnax.correlation_heatmap(correlations_filtered, p_values_filtered, figures_dir,  title = 'Selected Modules with cor>0,4', p_value_th=p_value_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some data about sleected modules\n",
    "\n",
    "significant_modules = []\n",
    "for trait in correlations.columns:\n",
    "    significant_clusters = np.abs(correlations[trait]) > threshold_of_interest\n",
    "    significant_clusters = significant_clusters[significant_clusters].index.tolist()\n",
    "    if significant_clusters:\n",
    "        for module in significant_clusters:\n",
    "            significant_modules.append(module)\n",
    "            print(f'Trait: {trait}  correlates with Module: {module}, showing a correlation of {correlations.at[module, trait]:.3f}')\n",
    "\n",
    "print('\\n')\n",
    "for module in set(significant_modules):\n",
    "    module_expression_profile = expression_profiles[expression_profiles['Module'] == module]\n",
    "    module_Genes = module_expression_profile['Gene Name'].tolist()\n",
    "    print(f'The module with id:{module} clusters {len(module_Genes)} genes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 9: Survival plot\n",
    "\n",
    "# Get the modules that show high correlations\n",
    "wgcnax.survival_probability(correlations, threshold_of_interest, expression_profiles, SurvivalData_for_TumorSamples, figures_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a Network Representation of the Relevant Clusters FOR TUMOR SAMPLES\n",
    "\n",
    "# Color mapping for different intervals of correlation strengths\n",
    "interval_colors = {\n",
    "    '0.9 - 1.0': 'red',\n",
    "    '0.8 - 0.9': 'orange',\n",
    "    '0.7 - 0.8': 'yellow',\n",
    "    '0.6 - 0.7': 'blue',\n",
    "    \n",
    "    '0.0 - 0.5': 'green',\n",
    "    }\n",
    "\n",
    "# Function to determine color based on weight\n",
    "def get_edge_color(weight, interval_colors):\n",
    "    for interval, color in interval_colors.items():\n",
    "        lower, upper = map(float, interval.split(' - '))\n",
    "        if lower <= abs(weight) <= upper:\n",
    "            return color\n",
    "    return 'grey'\n",
    "\n",
    "\n",
    "num_modules = len(set(significant_modules))\n",
    "grid_size = int(np.ceil(np.sqrt(num_modules)))\n",
    "plt.figure(figsize=(grid_size * 5, grid_size * 5))\n",
    "for i, cluster in enumerate(set(significant_modules), start = 1):\n",
    "    # Build Expression Profile for the Module\n",
    "    module_profile = expression_profiles[expression_profiles['Module'] == cluster].copy()\n",
    "    module_profile.set_index('Gene Name', inplace=True)\n",
    "    module_profile.drop('Module', axis=1, inplace=True)\n",
    "\n",
    "    # Add Eigengene\n",
    "    module_eigengene = eigengenes[eigengenes['Module'] == cluster].copy()\n",
    "    module_eigengene.set_index('Module', inplace=True)\n",
    "    module_eigengene.rename(index={cluster: 'EigenGene'}, inplace=True)\n",
    "    module_profile = pd.concat([module_profile, module_eigengene])\n",
    "\n",
    "    # Convert to numpy and calculate Spearman correlation -> Membership function in a way\n",
    "    module_profile_matrix = module_profile.to_numpy()\n",
    "    corr, _ = spearmanr(module_profile_matrix, axis=1)\n",
    "    corr_matrix = pd.DataFrame(corr, index=module_profile.index, columns=module_profile.index)\n",
    "    \n",
    "    # Network creation and node addition\n",
    "    G = nx.Graph()\n",
    "    for gene in module_profile.index:\n",
    "        G.add_node(gene)\n",
    "    \n",
    "    # Edge addition based on correlation\n",
    "    for gene1 in module_profile.index:\n",
    "        for gene2 in module_profile.index:\n",
    "            if gene1 != gene2:\n",
    "                weight = corr_matrix.loc[gene1, gene2]\n",
    "                color = get_edge_color(weight, interval_colors)\n",
    "                G.add_edge(gene1, gene2, weight=weight, color=color)\n",
    "    \n",
    "    # Plotting the network in a subplot\n",
    "    plt.subplot(grid_size, grid_size, i)\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=20)\n",
    "    edges = G.edges(data=True)\n",
    "    nx.draw(G, pos, with_labels=True, node_color=['red' if name=='EigenGene' else 'skyblue' for name in G.nodes], \n",
    "            node_size=500, \n",
    "            edge_color=[data['color'] for _, _, data in edges], linewidths=1, font_size=10,\n",
    "            width=[(data['weight'])*2 for _, _, data in edges])\n",
    "\n",
    "    plt.title(f'Module {cluster}')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# Add a legend for the whole figure\n",
    "title_figure = 'Network Representation of all Relevant Modules'\n",
    "legend_labels = {label: plt.Line2D([0], [0], color=color, lw=4) for label, color in interval_colors.items()}\n",
    "plt.figlegend(legend_labels.values(), legend_labels.keys(), loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.suptitle(title_figure, fontsize=20)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "plt.savefig(figures_dir + title_figure, dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WGCNA_approach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
