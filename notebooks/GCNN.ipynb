{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move out of the notebook folder to access datasets\n",
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('notebooks')\n",
    "data_dir = working_dir + 'data/PROTECTED_DATA/BGI_Expression_Data/'\n",
    "\n",
    "\n",
    "## Load Transcriptomics Data \n",
    "transcriptomics_TPM_dataset_dir = data_dir + 'CRC.SW.mRNA.symbol.TPM_NOnormal.csv'  \n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TPM_dataset_dir, index_col=0)\n",
    "\n",
    "# Classification Tags\n",
    "labels_classification_dir = data_dir + 'ClassTags_PrimarySiteDisease.csv' # Using only tumor samples\n",
    "labels = pd.read_csv(labels_classification_dir, index_col=0)\n",
    "\n",
    "\n",
    "# Figures Saving output dir\n",
    "\n",
    "\n",
    "# Convert The directory to the name of the column\n",
    "trait_used_as_label = labels_classification_dir.replace(data_dir, '').replace('ClassTags_', '').replace('.csv', '')\n",
    "trait_used_as_label = re.sub(r'(?<=\\w)([A-Z])', r' \\1', trait_used_as_label) # Add spaces before the capital letters for formatting\n",
    "\n",
    "# Convert labels to categorical values\n",
    "class_values = labels[trait_used_as_label].astype('category').cat.codes\n",
    "labels['label'] = class_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Make a subset to save RAM\n",
    "subset_dataset_size = 2000\n",
    "transcriptomics_dataset = transcriptomics_dataset.iloc[:, :subset_dataset_size] \n",
    "\n",
    "# RAM usage estimation in GB\n",
    "RAM_estimate = (subset_dataset_size * subset_dataset_size * 8) / (1024**3)\n",
    "print(f\"The aproximated RAM to analyse this size of dataset is: {RAM_estimate} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for the Model\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Preprocess the data using the same method as in the WGCNA approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_TPM_outlier_deletion(raw_data, expression_th):\n",
    "\n",
    "    \"\"\"\n",
    "    Cleans raw data by filtering out low expression genes, applying log transformation, and removing outliers based on PCA analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - raw_data (DataFrame): The raw data as a pandas DataFrame.\n",
    "    - expression_th (int): The value of expression under which genes are eliminated.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: The dataset after preprocessing and outlier removal.\n",
    "    \"\"\"\n",
    "    # Filter out genes with low expression across all samples\n",
    "    cleaned_dataset = raw_data.loc[:, (raw_data > expression_th).any(axis=0)].copy()\n",
    "    \n",
    "    # Apply log2 transformation to all values except for the first column (gene identifiers)\n",
    "    cleaned_dataset.iloc[:, 1:] = np.log2(cleaned_dataset.iloc[:, 1:] + 1)\n",
    "    \n",
    "    # Outlier detection and removal based on PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(cleaned_dataset.iloc[:, 1:])  # NOT Transpose to have samples as rows for PCA\n",
    "    z_scores = np.abs(stats.zscore(pca_result, axis=0))\n",
    "    good_samples = (z_scores < 3).all(axis=1)                      # Keeping samples within 3 standard deviations\n",
    "    cleaned_dataset = cleaned_dataset[good_samples]\n",
    "\n",
    "    # Data Standardization (Z-score normalization)\n",
    "    cleaned_dataset.iloc[:, 1:] = cleaned_dataset.iloc[:, 1:].apply(stats.zscore, axis=0)\n",
    "\n",
    "    # Print the number of genes removed\n",
    "    num_genes_removed = raw_data.shape[1] - cleaned_dataset.shape[1]\n",
    "    print(f\"preprocess_TPM_outlier_deletion function removed {num_genes_removed} genes\")\n",
    "\n",
    "    # Print the number of genes removed\n",
    "    num_pacients_removed = raw_data.shape[0] - cleaned_dataset.shape[0]\n",
    "    print(f\"preprocess_TPM_outlier_deletion function removed {num_pacients_removed} pacients\")\n",
    "\n",
    "    return cleaned_dataset\n",
    "\n",
    "def plot_pca(dataframe, title, ax = None):\n",
    "    \"\"\"\n",
    "    Performs PCA on the provided dataframe and plots the first two principal components for visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe (DataFrame): The dataframe to perform PCA on.\n",
    "    - title (str): The title of the plot.\n",
    "    \n",
    "    Returns:\n",
    "    - None, it generates the plot\n",
    "    \"\"\"\n",
    "    # Perform PCA analysis\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(dataframe.iloc[:, 1:].T)\n",
    "\n",
    "    # Plot the first two principal components\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "\n",
    "\n",
    "transcriptomics_clean = preprocess_TPM_outlier_deletion(transcriptomics_dataset, expression_th = 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_pca(transcriptomics_dataset, title='PCA of Original Data', ax=axs[0])\n",
    "plot_pca(transcriptomics_clean, title='PCA of Preprocessed with preprocess_TPM_outlier_deletion', ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph representation of the dataset\n",
    "\n",
    "We Tranform the dataset into a network representation. This can be done in many ways, we opt for a self-similarity matrix based on correlation as a metric of similarity\n",
    "\n",
    "As per the paper:\n",
    "To create the co-expression graph, Spearman correlation was calculated to generate a correlation matrix between each gene in the dataset.\n",
    "Spearman Correlation is a widely adopted method to assess monotonic linear or non-linear relationships in sequencing data. \n",
    "If the correlation between two genes is >0.6 with a p < 0.05, a weight of 1 is placed in an adjacency matrix, otherwise 0. If there is no correlation >0.6 with a given gene, then that gene is removed from the gene list, leading to the total of genes in the co-expression graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0: Turn dataframe into NumPy matrix for efficiency\n",
    "transcriptomics_np = transcriptomics_clean.to_numpy()\n",
    "\n",
    "# Step 1: Calculate Spearman Correlation and p-values\n",
    "correlations, pvalues = stats.spearmanr(transcriptomics_np)\n",
    "\n",
    "# Step 2: Construct the Adjacency Matrix\n",
    "adjacency_matrix_np = (correlations > 0.6) & (pvalues < 0.05)\n",
    "adjacency_matrix_np = adjacency_matrix_np.astype(int)\n",
    "adjacency_matrix = pd.DataFrame(adjacency_matrix_np, index=transcriptomics_clean.columns, columns=transcriptomics_clean.columns)\n",
    "\n",
    "# Step 3: Remove Isolated Genes - does not correlate >0.6 with any other gene\n",
    "is_not_isolated = adjacency_matrix.sum(axis=1) > 0\n",
    "filtered_adjacency_matrix = adjacency_matrix.loc[is_not_isolated, is_not_isolated]\n",
    "print(f'{transcriptomics_clean.shape[1]-filtered_adjacency_matrix.shape[0]} genes were removed as Isolated Genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Given 'transcriptomics_clean' DataFrame, ensure 'transcriptomics_np' is updated after filtering\n",
    "transcriptomics_np_filtered  = transcriptomics_clean.loc[:, is_not_isolated].to_numpy()\n",
    "\n",
    "# Step 1: Convert the filtered adjacency matrix to a sparse format\n",
    "sparse_adjacency_matrix = sparse.csr_matrix(filtered_adjacency_matrix.values)\n",
    "\n",
    "\n",
    "# Convert sparse adjacency matrix to TensorFlow sparse tensor\n",
    "adjacency_matrix_tensor = tf.sparse.SparseTensor(indices=np.array(list(zip(*sparse_adjacency_matrix.nonzero()))),\n",
    "                                                 values=sparse_adjacency_matrix.data.astype(np.float32),\n",
    "                                                 dense_shape=sparse_adjacency_matrix.shape)\n",
    "\n",
    "# Normalize adjacency matrix with added self-loops for GCN\n",
    "num_nodes = adjacency_matrix_tensor.dense_shape[0]\n",
    "indices = tf.concat([adjacency_matrix_tensor.indices, tf.range(num_nodes)[:, tf.newaxis], tf.range(num_nodes)[:, tf.newaxis]], axis=0)\n",
    "values = tf.concat([adjacency_matrix_tensor.values, tf.ones(num_nodes)], axis=0)\n",
    "dense_shape = adjacency_matrix_tensor.dense_shape\n",
    "adjacency_matrix_tensor_with_self_loops = tf.sparse.reorder(tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape))\n",
    "degree_matrix = tf.sparse.reduce_sum(adjacency_matrix_tensor_with_self_loops, axis=-1)\n",
    "degree_matrix_inv_sqrt = tf.pow(degree_matrix, -0.5)\n",
    "degree_matrix_inv_sqrt = tf.where(tf.math.is_inf(degree_matrix_inv_sqrt), 0., degree_matrix_inv_sqrt)\n",
    "D_inv_sqrt = tf.sparse.SparseTensor(indices=tf.range(num_nodes)[:, tf.newaxis].repeat(2, axis=1),\n",
    "                                    values=degree_matrix_inv_sqrt,\n",
    "                                    dense_shape=[num_nodes, num_nodes])\n",
    "normalized_adjacency_matrix = tf.sparse.sparse_dense_matmul(\n",
    "    tf.sparse.sparse_dense_matmul(D_inv_sqrt, adjacency_matrix_tensor_with_self_loops),\n",
    "    D_inv_sqrt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
